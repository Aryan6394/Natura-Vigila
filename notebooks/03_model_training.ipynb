{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1a9a805",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "## Multi-Task Endangered Species Classifier\n",
    "\n",
    "This notebook trains the multi-task CNN model for conservation status and geographic region prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff7db99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from src.multi_task_model import MultiTaskModel, save_multi_task_model\n",
    "from src.data_loader import create_dataloaders, load_species_data\n",
    "from config.model_config import MODEL_CONFIG, TRAINING_CONFIG, MODEL_PATHS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16763602",
   "metadata": {},
   "source": [
    "## Setup Device and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1551615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Display configuration\n",
    "print(\"\\nModel Configuration:\")\n",
    "print(f\"  Input size: {MODEL_CONFIG['input_size']}\")\n",
    "print(f\"  Batch size: {MODEL_CONFIG['batch_size']}\")\n",
    "print(f\"  Epochs: {MODEL_CONFIG['epochs']}\")\n",
    "print(f\"  Learning rate: {MODEL_CONFIG['learning_rate']}\")\n",
    "print(f\"  Dropout rate: {MODEL_CONFIG['dropout_rate']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2489bcda",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba1da87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset and create dataloaders\n",
    "print(\"Loading dataset...\")\n",
    "\n",
    "try:\n",
    "    dataset = load_species_data()\n",
    "    train_loader, val_loader, test_loader = create_dataloaders(\n",
    "        dataset, \n",
    "        batch_size=MODEL_CONFIG['batch_size']\n",
    "    )\n",
    "    print(f\"Train batches: {len(train_loader)}\")\n",
    "    print(f\"Validation batches: {len(val_loader)}\")\n",
    "    print(f\"Test batches: {len(test_loader)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    print(\"Please ensure dataset is available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359c53d4",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33d4a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize multi-task model\n",
    "print(\"Creating multi-task model...\")\n",
    "model = MultiTaskModel(pretrained=True)\n",
    "model = model.to(device)\n",
    "\n",
    "# Display model architecture\n",
    "print(\"\\nModel Architecture:\")\n",
    "print(model)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67198260",
   "metadata": {},
   "source": [
    "## Define Loss Functions and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9c4016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss functions\n",
    "conservation_criterion = nn.CrossEntropyLoss()\n",
    "geographic_criterion = nn.BCELoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(), \n",
    "    lr=MODEL_CONFIG['learning_rate']\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='min', \n",
    "    patience=TRAINING_CONFIG['reduce_lr_patience'],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"Loss functions and optimizer configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809cbee3",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09440d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_epoch(model, train_loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=\"Training\")\n",
    "    for images, conservation_labels, geographic_labels in pbar:\n",
    "        images = images.to(device)\n",
    "        conservation_labels = conservation_labels.to(device)\n",
    "        geographic_labels = geographic_labels.to(device).float()\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        conservation_pred, geographic_pred = model(images)\n",
    "        \n",
    "        # Calculate losses\n",
    "        loss_conservation = conservation_criterion(conservation_pred, conservation_labels)\n",
    "        loss_geographic = geographic_criterion(geographic_pred, geographic_labels)\n",
    "        \n",
    "        # Combined loss\n",
    "        loss = loss_conservation + 0.5 * loss_geographic\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "# Validation function\n",
    "def validate(model, val_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, conservation_labels, geographic_labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            conservation_labels = conservation_labels.to(device)\n",
    "            geographic_labels = geographic_labels.to(device).float()\n",
    "            \n",
    "            conservation_pred, geographic_pred = model(images)\n",
    "            \n",
    "            loss_conservation = conservation_criterion(conservation_pred, conservation_labels)\n",
    "            loss_geographic = geographic_criterion(geographic_pred, geographic_labels)\n",
    "            loss = loss_conservation + 0.5 * loss_geographic\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(conservation_pred, 1)\n",
    "            correct += (predicted == conservation_labels).sum().item()\n",
    "            total += conservation_labels.size(0)\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    return total_loss / len(val_loader), accuracy\n",
    "\n",
    "print(\"Training functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482eb51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main training loop\n",
    "num_epochs = MODEL_CONFIG['epochs']\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'val_accuracy': []\n",
    "}\n",
    "\n",
    "print(f\"Starting training for {num_epochs} epochs...\\n\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_accuracy = validate(model, val_loader, device)\n",
    "    \n",
    "    # Update scheduler\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_accuracy'].append(val_accuracy)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        save_multi_task_model(model, MODEL_PATHS['multi_task_model'])\n",
    "        print(\"âœ“ Model saved!\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    # Early stopping\n",
    "    if patience_counter >= TRAINING_CONFIG['early_stopping_patience']:\n",
    "        print(f\"\\nEarly stopping triggered after {epoch+1} epochs\")\n",
    "        break\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2028e945",
   "metadata": {},
   "source": [
    "## Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e287672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss plot\n",
    "axes[0].plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "axes[0].plot(history['val_loss'], label='Validation Loss', marker='s')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training and Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Accuracy plot\n",
    "axes[1].plot(history['val_accuracy'], label='Validation Accuracy', marker='o', color='green')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Validation Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/training_history.png', dpi=100)\n",
    "plt.show()\n",
    "\n",
    "print(\"Training history saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bfd101",
   "metadata": {},
   "source": [
    "## Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa90f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model\n",
    "final_model_path = MODEL_PATHS['multi_task_model']\n",
    "save_multi_task_model(model, final_model_path)\n",
    "\n",
    "print(f\"Final model saved to: {final_model_path}\")\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "print(\"\\nModel training complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
