{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "576e245d",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "## Endangered Species Image Classifier\n",
    "\n",
    "This notebook handles preprocessing of images and labels for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d93b179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.preprocessing import *\n",
    "from src.data_loader import *\n",
    "from config.model_config import MODEL_CONFIG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0f21a1",
   "metadata": {},
   "source": [
    "## Image Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f0f504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image transformations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(MODEL_CONFIG['input_size']),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(MODEL_CONFIG['input_size']),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"Transformations defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6049dd75",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e43536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test conservation label encoding\n",
    "test_labels = ['CR', 'EN', 'VU', 'NT', 'LC']\n",
    "print(\"Conservation Label Encoding:\")\n",
    "for label in test_labels:\n",
    "    encoded = encode_conservation_label(label)\n",
    "    decoded = decode_conservation_label(encoded)\n",
    "    print(f\"  {label} -> {encoded} -> {decoded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8ce9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test geographic region encoding\n",
    "test_regions = [['Africa'], ['Asia', 'Europe'], ['North America', 'Marine']]\n",
    "print(\"\\nGeographic Region Encoding:\")\n",
    "for regions in test_regions:\n",
    "    encoded = encode_geographic_regions(regions)\n",
    "    decoded = decode_geographic_regions(encoded)\n",
    "    print(f\"  {regions} -> {decoded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0e6127",
   "metadata": {},
   "source": [
    "## Create Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1813d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare dataloaders\n",
    "print(\"Creating data loaders...\")\n",
    "\n",
    "try:\n",
    "    dataset = load_species_data()\n",
    "    train_loader, val_loader, test_loader = create_dataloaders(dataset)\n",
    "    \n",
    "    print(f\"Train batches: {len(train_loader)}\")\n",
    "    print(f\"Validation batches: {len(val_loader)}\")\n",
    "    print(f\"Test batches: {len(test_loader)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating dataloaders: {e}\")\n",
    "    print(\"Will use placeholder data for demonstration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2084862e",
   "metadata": {},
   "source": [
    "## Visualize Augmented Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6181dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show examples of data augmentation\n",
    "print(\"Data augmentation examples:\")\n",
    "print(\"- Random horizontal flip\")\n",
    "print(\"- Random rotation (±15°)\")\n",
    "print(\"- Color jitter (brightness, contrast)\")\n",
    "print(\"- Normalization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f26cea",
   "metadata": {},
   "source": [
    "## Save Preprocessed Data Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b039921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessing configuration\n",
    "preprocessing_info = {\n",
    "    'input_size': MODEL_CONFIG['input_size'],\n",
    "    'normalization_mean': [0.485, 0.456, 0.406],\n",
    "    'normalization_std': [0.229, 0.224, 0.225],\n",
    "    'augmentation': ['horizontal_flip', 'rotation', 'color_jitter']\n",
    "}\n",
    "\n",
    "print(\"\\nPreprocessing Configuration:\")\n",
    "for key, value in preprocessing_info.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nData preprocessing complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
